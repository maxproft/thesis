\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{times}
\usepackage{graphicx}
\usepackage{url}
\usepackage{amsmath}
\usepackage{array}
\usepackage{mathtools}
\usepackage{ifthen}
\usepackage{mathrsfs}

\oddsidemargin 0.1in		% Left margin is 1in + this value
\textwidth 5.75in		% Right margin is not set explicitly
\topmargin 0in			% Top margin is 1in + this value
\textheight 8.5in			% Bottom margin is not set explicitly
%\setlength{\columnsep}{2cm}



\iffalse
These words need to be added to the dictionary:
Ginzburg, soliton, Runge, Kutta, CGLE, Fourier, Landau
discretise
Decide whether to use non linear, non-linear, nonlinear
\fi


\iffalse
\begin{figure}[h]
\centering
\includegraphics[width=4.6in]{correlation}
\caption{A ploperature.}
\label{corr} 
\end{figure}
\fi


\iffalse
Before I submit, make sure I check that the following have updated themselves properly.
Spell Check
Contents Page
Image reference numbers
Table reference numbers
Citation numbers
\fi






\begin{document}
\begin{titlepage}
\centering
{\ \\ }
\vspace{3cm}
{\bf  \fontsize{1.35cm}{2.5cm}\selectfont Soliton Solutions of the \vspace{0.5cm} Complex Ginzburg \\\vspace{0.5cm}Landau Equation}\\
\vspace{2cm}
{\Huge By Max Proft}\\
{\Huge u5190335}
\end{titlepage}










\newcommand{\unnum}[2]{
\ifthenelse{\equal{#1}{chapter}}{\chapter*{#2}}{
\ifthenelse{\equal{#1}{section}}{\section*{#2}}{
\ifthenelse{\equal{#1}{subsection}}{\subsection*{#2}}
{\chapter*{ERROR: #2}}}}
\addcontentsline{toc}{#1}{#2} 
}%This is the exception if no case matches!!!
\tableofcontents{}
\iffalse
The order is:
Chapter
Section
Subsection
Subsubsection (not shown in contents)
\fi






\unnum{chapter}{Abstract}
Abstract goes here.

\unnum{chapter}{Acknowledgements}
Chuck in some very cliché acknowledgements here.








\chapter{Introduction to the CGLE}
The Complex Ginzburg Landau equation (CGLE) is a differential equation that describes a range of quantum phenomena, such as ----------------. 
It is typically written in the following form:
$$i\psi_t +\frac{D}{2}\psi_{xx}+|\psi|^2\psi +\nu |\psi|^4\psi = i\delta \psi+i\epsilon|\psi|^2\psi +i\beta\psi_{xx}+i\mu|\psi|^4\psi$$
$\psi$ refers to the normalised field (normalised with respect to what?)\\
$D = \pm 1$. if $D=1$ then normal. This means that as the optical frequency increases, the group velocity decreases. If $D=-1$ then the group velocity dispersion is anomalous, which is the opposite.\\
$\beta>0$ is parabolic gain and $\beta<0$ effectively means that sharp spikes are filtered out. (This doesn't make sense - shouldn't it be the other way around?)
 causes spectral filtering\\
$\delta$ is the linear gain/loss depending on whether it is positive/negative. \\
$\epsilon$ is nonlinear gain which can arise for a variety of reasons, such as saturable absorption (absorbtion decreases/reflectivity increases as intensity increases.)\\
$\mu$ and $\nu$, when negative, represents the saturation of the NL gain and NL refractive index respectively. 







\chapter{Derivations of the CGLE}
\section{For a Quantum System}
\section{For a Classical System}












\chapter{Types of solitons}
There are many types of solitons, however an explicit expression for the function usually cannot be found. 

While many explicit solutions for the schrodinger equation have been found, with additional nonlinearity means that finding explicit solutions to the CGLE is often not possible.
\\\\
(Jia-Min Zhu and Zheng-Yi Ma (2007),Pierre Hillion (2012), Mihalache and Panoiu (1992), Yan-Ze Peng and Krishnan (2007) =  Schrodinger equation)
\\\\
We can classify solitons depending on their behaviour.
Stationary solitons maintain a constant amplitude.
Pulsating solitons are another type, and can be categorised into subsets such as "plain pulsating",  "exploding" and creeping. \\\\
Plain pulsating solitons are periodic and don't exhibit any significant features, as given in figure \ref{plain}.
\begin{figure}[h]
\centering
\includegraphics[width=2.6in]{plain}
\caption{The 2D plot of a plain pulsating soliton with parameters ..........}
\label{plain} 
\end{figure}
Exploding solitons are characterised by a sharp jumps in their energy profile, as given in figure \ref{expl_profile}, with the 2D intensity given in figure \ref{expl}. Other solitons will, instead of exploding outwards, give a high intensity spike, as in figure \ref{highamp} whose energy increases by >10 times because of the spike
\begin{figure}[h]
\centering
\includegraphics[width=2.6in]{expl_profile}
\caption{The profile of an exploding soliton with parameters ..........}
\label{expl_profile} 
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=2.6in]{expl}
\caption{The 2D intensity of an exploding soliton with parameters ..........}
\label{expl} 
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=2.6in]{highamp}
\caption{The 2D intensity of a high amplitude soliton with parameters ..........}
\label{highamp} 
\end{figure}
As parameters are varying, unusual behaviour can also be seen. 
For example, with the set of parameters (---------), when varying $\epsilon$, periodic doubling can be seen, as in figure \ref{periodic_doubling}. As the parameter c is increased, the the height of the solitons changes to a period 2 then a period 4 cycle. 
\begin{figure}[h]
\centering
\includegraphics[width=2.6in]{periodic_doubling}
\caption{The energy profile of 3 solitons, with periodic doubling being seen. Parameters .........., for these images, the actual domain is from 0 to 100.}
\label{highamp} 
\end{figure}

We also get solitons that creep sideways as they oscillate.
An example is given in figure ------- of a soliton that creeps to the right forever. Another example is in figure \ref{periodpulse} 
\begin{figure}[h]
\centering
\includegraphics[width=2.6in]{periodpulse}
\caption{A creeping, pulseating soliton that is also periodic. Note that the weird patterning inside the image is from aliasing. params ---------}
\label{periodpulse} 
\end{figure}



\chapter{Mathematical Theory Behind Solving the CGLE}
\section{A Comparison of Different Methods}

A finite difference method was used initially to get it all going. This is bad because you do $\delta \psi / \delta x$, so over a small time period, the $\delta \psi$ term can lose several digits of precision, not good. There are a number of other ways for this to be solved though. 
\\\\ 
For the nonlinear schrodinger equation, (Taha and Ablowitz) compared various methods for solving this. While under certain conditions, some other methods were found to be better than the split step fourier method, overall it was found to be a faster algortihm. Given that the CGLE is an extension of the NLSE, this means that this should also be a reasonably good method to do this part as well. This has previously been done by other authors as well, (Wang, Zhang).

\section{Split Step Fourier and Runge-Kutta Method}
\subsection{Linear evolution (Fourier)}
Here we are solving the equation: 
$$\frac{d\psi}{dt}=A\frac{d^2\psi}{dx^2}+B\psi$$
Defining the fourier transform by: 
$$\hat \psi(f)=\int\limits_{-\infty}^\infty \psi(x)e^{-i2\pi x f} dx$$
By taking the fourier transform of both sides, the equation becomes:\\
$$\frac{d \hat \psi}{dt}= C(-2\pi i f)^2 D\hat \psi (f)+\hat \psi(f)= (C-D4 \pi^2 f^2) \hat \psi(f)$$
$$\implies \hat \psi_t(f) = e^{(C-D4\pi^2 f^2)t}\hat \psi_0(f)$$
And so upon inverse fourier transforming, we get the solution to this DE, where $\hat \psi_t(f)$ is the fourier transform at time $t$.
The Fourier transform can be done numerically with a discrete fourier transform, as described in a later subsection.

\subsection{Nonlinear evolution (Runge-Kutta)}
Here we are solving the equation:
$$\frac{d\psi}{dt}=C|\psi|^2\psi + D|\psi|^4\psi$$
The runga kutta method allows you to numerically solve a 1st order differential equation. which are of the form $\frac{dy}{dt}=f(t,y)$. Similar to Euler's method (which is basically just doing a derivative from first principles), except that the runge kutta method has better convergence than this. (it goes as $h^5$ as opposed to Euler's Method which is $h^2$, the backward euler formula, $h^2$, or improved euler formula which goes as $h^3$. Here $h$ is the step size. 
\\\\
The steps for doing this are as follows:
Step 1: define $f(t,y)=f(y)=C|y|^2 y  +D|y|^4 y$
Step 2: Have an initial value for $t$ and $y$, and step size and number of steps
Step 3: define the following:
$$K_1 =f(t,y)=f(y)$$
$$K_2 =f(t+0.5h,y+0.5*h*K_1)=f(y+h*K_1/2)$$
$$K_3 =f(t+0.5h,y+0.5*h*K_2)=f(y+h*K_2/2)$$
$$K_4 =f(t+h,y+h*K_3)=f(y+h*K_3)$$
Step 4: we then progress forwards $t$ and $y$ in the following way:
$$t\rightarrow t+h$$
$$y\rightarrow y+(K_1+2K_2+2K_3+K_4)*h/6$$






\iffalse
\subsection{The relationship between a Fourier Transform and a Discrete Fourier Transform}
I am pretty sure this entire section needs to be rewritten.\\
We can approximate any function with a Fourier series. (by applying periodic boundary conditions)\\
$$f(t)=\sum\limits_{-\infty}^{\infty} c_n e^{i n t}$$
Multiplying both sides by $e^{-i m t}$ and integrating from 0 to $2\pi$, and dividing by $2\pi$:
$$\frac{1}{2\pi} \int\limits_{0}^{2\pi} f(t)e^{-i m t}dt = \frac{1}{2\pi} \sum \limits_{n=-\infty}^{\infty} c_n \int\limits_{0}^{2\pi} d^{i (n-m) t} dt= c_m$$
$$\frac{1}{2\pi} \int\limits_{0}^{2\pi} f(t)e^{-i m t}dt =c_m$$
We use the substitution:
$$t = \frac{2\pi}{L}  x \implies x = \frac{L}{2\pi} t$$
$$dt = \frac{2\pi}{L}  dx$$
And then this becomes:
$$c_m = \frac{1}{L} \int\limits_{0}^{L} f(x) e^{-i m 2\pi x/L} dx $$

For a fourier series $\{c_n\}$, the fourier transform is given given by:

$$\hat f (freq) = \sum\limits_{-\infty}^{\infty} c_n \mathscr{\hat F}(e^{i n 2 \pi x/L})(freq)$$ 

But we have $$\mathscr{\hat F}(e^{i n 2 \pi x/L}) = \int\limits_{-\infty}^\infty e^{i n 2 \pi x/L}e^{-i 2\pi freq x} dx $$
$$= \int\limits_{-\infty}^\infty e^{i x (n 2 \pi /L - 2\pi freq )}dx = 2\pi \delta (n 2\pi/L -2\pi freq)= \delta (n /L - freq)$$

And so we get:
$$\hat f (freq) = \sum\limits_{-\infty}^{\infty} c_n \delta(freq.- n/L)$$
$$= \sum\limits_{-\infty}^{\infty} c_n /L \delta(freq. L- n)$$

If we inverse fourier transform we get the following.
We can also use $x/L=n/N$
$$Data = spacial,  Fata=frequency$$


I don’t think the following is useful:
$$f(x)= \sum\limits_{n=-\infty}^\infty f_n e^{2\pi i n x/L} $$
If we multiply both sides by $e^{-2\pi i m x/L}$ and integrate we get:
$$\int \limits_{-\infty}^\infty f(x)e^{2\pi i n x/L} dx = \sum\limits_{n=-\infty}^\infty  f_n  \int \limits_{-\infty}^\infty  e^{i 2 \pi x/L (n-m)} dx  =  \sum\limits_{n=-\infty}^\infty  f_n  \int \limits_{-\infty}^\infty  e^{i 2 \pi x (n-m)/L} dx  $$
$$=  \sum\limits_{n=-\infty}^\infty  f_n \delta((n-m)/L) = f_n \delta((n-m)/L)$$
\fi




\subsection{The relationship between a Fourier Transform and a Discrete Fourier Transform:}
Below works for periodic boundary conditions, or if you assume that the function goes to zero at the boundary. For ease of proving the relationship, we assume the latter. 
\\\\
Defining the Fourier transform as:
$$\tilde \psi(f) = \int_{-\infty}^\infty \psi(x) e^{-i2\pi xf} dx \approx \int_0^L\psi(x)e^{-i2\pi x f}dx$$
Let $\Delta x=L/N$ for some integer $N$.
$$\approx \sum\limits_{n=0}^{N-1}\psi(n \Delta x) e^{-i 2\pi n \Delta x f}\Delta x$$
With the same arguments, we get the inverse Fourier transform to be:\\ 
($\Delta f = (f_1-f_0)/N$, for some values of $f_1$ and $f_2$)
$$\psi(x) = \int_{-\infty}^\infty \tilde\psi(f)e^{i 2\pi x f} df \approx \int_{f_0}^{f_1}\tilde\psi(f)e^{i 2\pi x f}df \approx \sum\limits_{m=0}^{N-1}\tilde\psi(f_0+m\Delta f)e^{i 2\pi n\Delta x f_0} e^{i 2\pi x m\Delta f}\Delta f$$
Let $\psi(n\Delta x) = \psi_n$ and $\tilde\psi(f_0+m\Delta f) = \tilde \psi_m$ and let $f_0=-\pi/\Delta x$ 
$$\tilde \psi_m\approx \Delta x \sum\limits_{n=0}^{N-1}\psi_n e^{-i 2\pi n \Delta x f_0}e^{-i 2\pi n m \Delta x \Delta f}$$
$$\psi_n  \approx \Delta f e^{i 2\pi n\Delta x f_0}\sum\limits_{m=0}^{N-1}\tilde\psi_m e^{i 2\pi n m \Delta x \Delta f}$$
Since the definition of the discrete Fourier transform is
$$\tilde A_m =  \sum\limits_{n=0}^{N-1} A_n e^{-i 2\pi n m/N}$$
$$A_n  = \frac{1}{N}\sum\limits_{m=0}^{N-1}\tilde A_m e^{i 2\pi n m/N}$$
We now have a way to compute (inverse) Fourier transforms given a set of data that is a sufficiently good approximation of the initial function.
\\\\
We want $f_1-f_0=1/\Delta x$ so that the frequency difference corresponds to the difference between adjacent elements. This means we get $\Delta f = 1/(N\Delta x)$. We then choose to take $f_0=\frac{-1}{2\Delta x}$ is chosen so it satisfies the Nyquist limit.
$$\tilde \psi_m\approx \Delta x \sum\limits_{n=0}^{N-1}\psi_n e^{i \pi n }e^{-i 2\pi n m/N}=\Delta x \sum\limits_{n=0}^{N-1}\psi_n (-1)^n e^{-i 2\pi n m/N}$$
$$\psi_n  \approx \frac{e^{-i \pi n}}{N\Delta x}\sum\limits_{m=0}^{N-1}\tilde\psi_m e^{i 2\pi n m/N}=\frac{(-1)^n }{N\Delta x}\sum\limits_{m=0}^{N-1}\tilde\psi_m e^{i 2\pi n m/N}$$


\subsection{Combining these operations}
With the split step fourier method, we assume that the linear and nonlinear terms do not affect each other over short timescales. This means that we can propegate forwards according to the linear evolution equation, and then propegate forwards according to the nonlinear evolution equation, and we should get a good approximation for the solution to the original differential equation. This can be represented as the following, where $\hat N$ refers to the nonlinear evolution operator, and $\hat L$ refers to the linear evolution operator.
$$\psi(t)=e^{\hat N(t)}e^{\hat L(t)}\psi(0)$$ 
It turns out, however, that a more stable way of doing this evolution is with the following (notice that the two outside terms are both evolution operators for half of the time period):
$$\psi(t)=e^{\hat N(t/2)}e^{\hat L(t)}e^{\hat N(t/2)}\psi(0)$$ 


Baker Campbell Hausdoff
Lie Product Formula
Trotter Product Formula



\section{Testing the Code}
I compared with mathematica and got the same answer with initial conditions ------ and step size ------ for both the linear and NL parts.\\
Also I subbed in exact solns to the NLSE and it matched.\\
Upon decreasing the step size, if the solution doesn't change significantly, we expect a very similar answer. \\
\\
Additionally, as previously done, there are a number of papers which give interesting solutions to the CGLE, and we can reproduce these solitons.











\chapter{Machine Learning Theory}
\section{Different Types of Machine Learning}
I want to enter in an image, and get it to tell me if it is oscillating/etc.\\
I want another machine learning algorithm to predict the required precision, and wait time before recording the output.\\
Monte Carlo and gradient descent to find new solns.\\
\section{Linear Regression}
Former Title: Different Options for the Machine Learning Algorithm\\
Another Title Removed: A detailed look at neural networks\\
\\
Step 1: Define a cost function:\\
Suppose we have input parameters $\vec x_i$ with the true value given by $y_i$. For linear regression, we choose $\vec\theta$ such that our prediction for the value of $y_i$ is $\vec\theta \cdot \vec x_i$. We want to vary the vector $\vec \theta$ such that the predictions match as best as possible. This is typically done by providing a cost function that is lowest when the predictions match the true value best. A typical cost function is (least squares):
$$J_\theta = \sum_i \left(\vec\theta\cdot \vec x_i -y_i\right)^2 $$
\\
Suppose we have two parameters, we might get an image as shown below. 
\begin{figure}[h]
\centering
\includegraphics[width=3in]{GradDescent}
\caption{Gradient descent example}
\label{corr} 
\end{figure}
The minimum of this graph give $\theta$ which causes the best predictions. 
Typically the algorithm to find the minimum is done by continually taking the steepest path. However the algorithm may end up finding a local minima, as in the subsequent figure. 
\begin{figure}[h]
\centering
\includegraphics[width=2in]{localmin}
\caption{Gradient descent example}
\label{corr} 
\end{figure}
Octave has lots of fancy functions that can do this really efficiently, and can try to avoid local minima.
\\\\
We can increase the number of input features. One feature we want to add is an intercept term, which will equal $1$ for every training example. Other features we might want to add, for example, would be the polynomial features $\{x_1^2,x_1x_2,x_1x_3, ... \}$. However if we add in these extra features, we are faced with another issue, and that is overfitting. If we have a high degree polynomial, it becomes much easier to overfit the data. In order to prevent this, we can adjust the cost function to:
$$J_\theta = \frac{1}{2m}\sum_i \left(\vec\theta\cdot \vec x_i -y_i\right)^2 +\frac{\lambda}{2m} |\vec\theta|^2$$
By doing this, if several of the elements of $\vec \theta$ are large, then the cost will increase, and so only the important features will remain large. However for this to work we must normalise the data, and in my program this is done by transforming each feature $x_i^{(j)}$  in the following manner, where the $i$ indicates that it is the $i^{th}$ training example, and the $j$ index refers to the $j^{th}$ component of the vector. Below $\mu^{(j)}$ refers to the mean of the $j^{th}$ component of all the training examples, and $\sigma^{(j)}$ the standard deviation
$$x_i^{(j)}\rightarrow \frac{x_i^{(j)}-\mu^{(j)}}{\sigma^{(j)}}$$
This ensures that all of the features are on the same scale, and so the elements of $\theta$ are penalised equally by the cost function. 



\section{Training and Testing the Algorithm}

Tried initially with only linear terms, then expanded to polynomial terms with regularisation and it was able to fit data with polynomial features $(0.5x_1+x_2^3)$. This game me the confidence that the algorithm was working correctly, and so I could go ahead and train the algorithm on real data with confidence.\\\\
My algorithm went up to 4th order polynomial terms, and with 6 different parameters being varied, this results in a total of 210 features. 










\chapter{The result from much work}
\section{The sorts of things that I found}












\unnum{chapter}{Conclusion}
\unnum{chapter}{Appendix A}
\unnum{chapter}{Appendix B}

\begin{thebibliography}{9}
%Introduction
\bibitem{RefExample}
    Name \emph{Title},
    Publishing info, etc
\bibitem{Ref2}
    Another Guy \emph{title2}
    pub,etc.
%Derivation of CGLE

%Types of Solitons

%Mathematical theory behind solving CGLE

%Machine Learning

%My solitons


\end{thebibliography}


\end{document}